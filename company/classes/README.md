---
description: 머신 러닝 및 딥러닝 교육용 리스소
---

# Classes

W&B는 학습 및 공동작업용으로 훌륭한 툴입니다. 저희는 무료 아카데믹 계정을 제공하고 있으며, 여러분과 여러분의 학생들이 복잡한 머신 러닝 프로젝트를 탐색을 돕고자 몇 가지 유용한 리소스를 모았습니다.

### **특징**

 **아카데믹 팀**

[아카데믹 팀](https://www.wandb.com/academic)을 요청하여 학생들이 공유 작업공관에 결과를 제출하도록 시작하세요. 현실적인 추적 결과 및 학생들이 모델 생성에 사용한 코드를 직접 보면 프로젝트 평가가 쉬워집니다.

**리포트**

학생들에게 리포트 제출을 요구하여, 결과를 탐색하고 새 프로젝트와 이전 베이스라인을 비교하실 수 있습니다. 리포트를 통해 중간 결과를 쉽게 설명할 수 있으며, 진행상황을 나타낼 수 있고, 모든 그래프는 재현 할 수 있는 실제 모델 결과와 연결되어 있습니다. [예시 리포트 보기 →](https://app.wandb.ai/stacey/keras_finetune/reports/Curriculum-Learning-in-Nature--Vmlldzo1MjcxNw)​

 **경연대회**

아카데믹 팀에 프로젝트를 생성하고, 학생들이 공동 과제에서 최고의 정확성을 얻기 위해 서로 경쟁하게끔 할 수 있습니다. 다음은 예시 경연대회 스크린샷입니다. 각 행은 서로 다른 실험이며, 사용자는 가장 높은 정확성을 위해 서로 경쟁하고 있습니다. [프로젝트 보기 →](https://app.wandb.ai/wandb/feb8-emotion)​

![](../../.gitbook/assets/image%20%2857%29%20%284%29%20%284%29.png)

## **리소스**

###  **예시 스크립트 repo**

저희는 다양한 프레임워크에서 딥러닝 프로젝트의 여러 작업 예시를 구축했습니다.

[GitHub repo 보기 →](https://github.com/wandb/examples)​

![](../../.gitbook/assets/image%20%2848%29%20%282%29%20%281%29.png)

 저희는 무료로 학생들이 몇 번의 마우스 클릭만으로 훈련을 실행할 수 있는 모델이 포함된 호스팅 notebook도 생성했습니다.

* 스크린샷을 포함한 [PyTorch](http://bit.ly/wandb-pytorch-intro) 소개
* [Keras ](http://bit.ly/wandb-keras-colab)MNIST 예시
* [TensorFlow 2](http://bit.ly/wandb-tf-colab) 합성곱 신경망

###  **튜토리얼**

Lunkas 와 Chris는 각 클래스 섹션에 노트를 포함한 짧은 튜토리얼 프로젝트 라이브러리를 구축했습니다. 질문사항이 있으시면 vanpelt@wandb.com으로 문의해주시기 바랍니다.

[튜토리얼 보기 →](https://www.wandb.com/tutorials)​

![](../../.gitbook/assets/image%20%2876%29%20%283%29%20%281%29.png)

###  **무료 클래스**

다음은 웹에서 제공되는 훌륭한 비디오, 노트 및 슬라이드입니다. 머신 러닝에 관한 모든 커리큘럼에 훌륭한 추가 자료로 활용하실 수 있습니다.

1. [Introduction to Machine Learning for Coders](http://course18.fast.ai/ml): 비디오, 예시 코드 및 지원에 관한 활기찬 포럼을 포함한 훌륭한 fastai 과정입니다.
2. [Full Stack Deep Learning](https://fullstackdeeplearning.com/march2019): 저희 친구, Josh Tobin이 가르치는 이 굉장한 수업은 딥러닝 모델 구축에 대한 전문 지식을 한 단계 업그레이드해드립니다
3. [Stanford CS230 Deep Learning](https://cs230.stanford.edu/): Andre Ng가 진행하는 훌륭한 스탠포드 과정으로, 강의와 슬라이드가 온라인으로 제공됩니다
4. [MIT Intro to Deep Learning](http://introtodeeplearning.com/):  Alexander Amini와 Ava Soleimany가 수업하는 이해하기 쉬운 입문과정입니다.

###  **슬라이드덱**

1. [Troubleshooting Deep Neural Networks](http://josh-tobin.com/troubleshooting-deep-neural-networks.html): 모델 디버깅에 대한 Josh Tobin의 훌륭한 슬라이드 덱입니다.
2. [Sequence to sequence models](https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf): 스탠포드의 컴퓨터 언어학 클래스의 슬라이드입니다.
3. [Transfer and multi-task learning](http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_15_multi_task_learning.pdf): 버클리의 Sergey Levine
4. [Transfomer models](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/lecture12.pdf): 스탠포드의 Richard Socher

##  **토픽**

### Seq2Seq

1. [Keras intro to seq2seq](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html): Keras 팀이 제작한 빠른 입문서
2. [Original paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf): Google의 Ilya Sutskever 및 동료들
3. [Berkeley slides](https://courses.d2l.ai/berkeley-stat-157/units/seq2seq.html): 인코더-디코더, seq2seq 및 머신 번역

###  **자연어 예시**

1. [OpenAI GPT-2](https://openai.com/blog/better-language-models/): 현실적인 텍스트 생성을 위한 모델
2. [TalkToTransformer.com](https://talktotransformer.com): GPT 2 해보기
3. [GLUE Benchmark](https://gluebenchmark.com/): 자연어 시스템 훈련 및 분석을 위한 리소스
4. [SuperGLUE](https://super.gluebenchmark.com/): 업데이트되고 향상된 GLUE 벤치마크의 v2
5. [Livox](http://impact-transfer.org/zero/livox/): 대체 의사소통 앱에서 NLP 사용
6. [Practical Twitter Content Mining](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3694275/): 트위터에서 NLP를 사용하는 것에 대한 의학 저널 기사
7. [Applications of NLP](https://medium.com/@datamonsters/artificial-neural-networks-in-natural-language-processing-bcf62aa9151a): 10가지 흥미로운 어플리케이션에 관한 주제를 다룬 Medium 기사
8. [Zero-shot transfer learning + LSTMs](https://www.media.mit.edu/publications/zero-shot-transfer-learning-to-enhance-communication-for-minimally-verbal-individuals-with-autism-using-naturalistic-data/): 최소 언어 단위에 대한 번역 기술 향상

저희는 학생을 가르치는 여러분을 지원하고 싶습니다. support@wandb.com으로 연락해주시기 바랍니다.

