# Useful resources

### Academic papers

Li, Lisha, et al. "[Hyperband: A novel bandit-based approach to hyperparameter optimization.](https://arxiv.org/pdf/1603.06560.pdf)" _The   Journal of Machine Learning Research_ 18.1 (2017): 6765-6816.

### Sweep Experiments

The following W\&B Reports demonstrate examples of projects that explore hyperparameter optimization with W\&B Sweeps.&#x20;

* <mark style="color:blue;"></mark>[Drought Watch Benchmark Progress](https://wandb.ai/stacey/droughtwatch/reports/Drought-Watch-Benchmark-Progress--Vmlldzo3ODQ3OQ)
  * Description: Developing the baseline and exploring submissions to the Drought Watch benchmark.
* [Tuning Safety Penalties in Reinforcement Learning](https://wandb.ai/safelife/benchmark-sweeps/reports/Tuning-Safety-Penalties-in-Reinforcement-Learning---VmlldzoyNjQyODM)
  * Description: We examine agents trained with different side effect penalties on three different tasks: pattern creation, pattern removal, and navigation.
* [Meaning and Noise in Hyperparameter Search with Weights & Biases](https://wandb.ai/stacey/pytorch\_intro/reports/Meaning-and-Noise-in-Hyperparameter-Search--Vmlldzo0Mzk5MQ) [Stacey Svetlichnaya](https://wandb.ai/stacey)
  * Description: How do we distinguish signal from pareidolia (imaginary patterns)? This article is showcases what is possible with W\&B and aims to inspire further exploration.
* [Who is Them? Text Disambiguation with Transformers](https://wandb.ai/stacey/winograd/reports/Who-is-Them-Text-Disambiguation-with-Transformers--VmlldzoxMDU1NTc)
  * Description: Using HuggingFace to explore models for natural language understanding
* [DeepChem: Molecular Solubility](https://wandb.ai/stacey/deepchem\_molsol/reports/DeepChem-Molecular-Solubility--VmlldzoxMjQxMjM)
  * Description: Predict chemical properties from molecular structure with random forests and deep nets.
* [Intro to MLOps: Hyperparameter Tuning](https://wandb.ai/iamleonie/Intro-to-MLOps/reports/Intro-to-MLOps-Hyperparameter-Tuning--VmlldzozMTg2OTk3)
  * Description: Explore why hyperparameter optimization matters and look at three algorithms to automate hyperparameter tuning for your machine learning models.

### How-to-guides

The following how-to-guide demonstrates how to solve real-world problems with Weights & Biases:

* [Sweeps with XGBoost ](https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-xgboost/xgboost\_tune.py)
  * Description: How to use W\&B Sweeps for hyperparameter tuning using XGBoost.

### Sweep GitHub repository

Weights & Biases advocates open source and welcome contributions from the community. Find the GitHub repository at [https://github.com/wandb/sweeps](https://github.com/wandb/sweeps). For information on how to contribute to the Weights & Biases open source repo, see the W\&B GitHub [Contribution guidelines](https://github.com/wandb/wandb/blob/master/CONTRIBUTING.md).&#x20;

